进程：cpu最小分配单元，每个运行中的程序至少包含一个进程，不同进程使用不同内存空间


多进程方式一(fork函数, 适用于Unix/GNU Linux/Mac):
fork()函数返回两次. 在父进程中返回子进程的ID, 在子进程中返回0
例.
import os

print('Process %s start.'%os.getpid())
pid = os.fork()
if pid == 0:
	print('I am child process %s, i inherit from process %s.'%(os.getpid(), os.getppid()))

结果
Process 6535 start.
I am parent process 6535, i have a child process 6536.
I am child process 6536, i inherit from process 6535.


多进程方式二(multiprocessing.Process类和multiprocessing.pool.Pool类, 适用于Unix/GNU Linux/Mac/Windows系统):
例1.
from multiprocessing import Process
import os

def run_proc(name):
    print('Run child process %s (%s)...' % (name, os.getpid()))

if __name__=='__main__':
    print('Parent process %s.' % os.getpid())
    p = Process(target=run_proc, args=('test',))
    print('Child process will start.')
    p.start()
    p.join()
    print('Child process end.')

例2.
子进程跟随父进程结束(子进程为daemonic进程)
import multiprocessing, time, os

def f(proc_name):
	print("%s的进程ID: %s." % (proc_name, os.getpid()))
	print("%s的父进程ID: %s." % (proc_name, os.getppid()))
	time.sleep(20)
	print("进程%s is done." % os.getpid())

if __name__ == "__main__":
	print("%s的进程ID: %s." % (multiprocessing.current_process().name, os.getpid()))
	process = multiprocessing.Process(target=f, args=("sub_proc",), daemon=True)
	process.start()
	time.sleep(5)
	print("进程%s is done." % os.getpid())


三种启动子进程的方式:
1.spawn - 只从父进程继承必要的资源. 速度比fork/forkserver慢得多. 支持Unix/Mac/Windows, 在Mac和Windows为默认选项

2.fork - 完整继承父进程资源. 无法使用该方法启动多线程的进程. 支持Unix/Mac, 在Unix中为默认选项

3.forkserver - 启动一个server process, 每当需要启动新的process时, 父进程连接到server procee, server process会fork一个新进程. server process为单线程进程. 只在可用pipe传递文件描述符的Unix系统中支持


multiprocessing模块
function:
cpu_count()
	当前系统cpu数量

current_process()
	返回当前进程对象

parent_process()
	返回当前进程的父进程对象

Pipe(duplex=True)
	创建一个管道，返回(conn1, conn2)， 即一对Connection对象
	duplex - 当为True，管道为双工管道；当为False时，单工管道，conn1只能接收信息，conn2只能发送信息

class
Process
variabl:
daemon
	设置或获取进程是否为daemon进程
	进程的初始daemon继承于父进程
	进程结束时，试图中断所有daemonic子进程
	daemonic进程不允许创建子进程，当其daemonic的父进程结束时，它跟着结束，并将其子进程遗留为孤儿进程
	daemonic进程不同于Unix daemon程序概念

exitcode
	子进程的exit code

name
	赋值或获取进程名

pid
	进程id

method:
__init__(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)
	创建一个子进程
	group - 保留, 主要与threading.Thread格式兼容
	target - 可调用的function, 被子进程的run()方法调用的函数
	name - str类型，进程的名称，默认为'Process-<N>'
	args - tuple类型，传入target方法的位置参数
	kwargs - dict类型，传入target方法的关键字参数
	daemon - bool类型，设置进程是否为守护线程。默认继承自父进程

close()
	关闭进程

is_alive()
	进程是否正在运行，返回bool对象

join(timeout=None)
	子进程阻塞父进程，直到子进程结束
	timeout - 子进程阻塞指定时间，后续分离执行

kill()
	SIGKILL signal中断

start()
	启动子进程，实质上调用run()

terminate()
	SIGTERM signal中断


例3.
所有进程在进程池中处于同一个队列, sync进程会阻塞不让下一个进程执行, async不会如此



例4.
Pool类的map不会在进程在进行阻塞
import time, os, random
from multiprocessing.pool import Pool

def pow_num(x):
    pro = x*x
    print(pro)
    r = random.randint(10, 20)
    time.sleep(r)
    print('process id: %s, execute %d s.'%(os.getpid(), r))

p = Pool(4)
start = time.time()
l = range(1, 11)
p.map(pow_num, l, chunksize=2)
p.close()
p.join()
end = time.time()
print("cost time %.2f"%(end-start))
print("maip process is done.")


multiprocessing.pool模块
class
Pool
method:
__init__(processes=None, initializer=None, initargs=(), maxtasksperchild=None, context=None)
	创建进程池. 参数列表如下:
		processes - 进程池中的进程数量. 默认为os.cpu_count()返回的值
		initializer - 当不为None时, 进程池中的每个进程都调用该可调用函数
		initargs - 可调用函数的位置参数列表
		maxtasksperchild - 进程执行指定任务数量后关闭. 默认为存活直到线程池关闭

apply(func, args=(), kwds={})
	启动sync进程, 需要进程池中的上一个运行进程完毕, 再执行下一个进程. 参数列表如下:
	func - 调用的函数
	args - tuple格式，传递给调用函数的位置参数
	kwds - dict格式，传递给调用函数的关键字参数

apply_async(func, args=(), kwds={}, callback=None, error_callback=None)
	启动async进程, 进程池中的进程可随时切换执行
	func - 调用的函数
	args - tuple格式，传递给调用函数的位置参数
	kwds - dict格式，传递给调用函数的关键字参数

close()
	阻止新进程加入进程池

imap(func, iterable, chunksize=1)
	慵懒版本的map, 可用于处理大型iterables

join()
	进程池进程阻塞主进程

map(func, iterable, chunksize=1)
	将iterable中的元素逐个执行func的操作. 类似于built-in指令map. 块内保持同步阻塞(非进程间, 而是进程内的块单元操作). 参数列表如下:
		func - 可迭代对象中元素执行的操作
		iterable - 可迭代对象
		chunksize - 将可迭代对象切分的大小, 该切分后的块分配给不同process

map_async(func, iterable, chunksize=1, callback=None, error_callback=None)
	类似于map

terminate()
	马上中断进程池中所有进程


进程间通信方式一(multiprocessing.Queue类和multiprocessing.Pipe函数):
multiprocessing.connection模块
class - Connection

method:
close()
	关闭连接

recv()
	接收另一端发送的信息，阻塞直到另一端发送信息
	当阻塞阶段，另一端主动关闭，抛出EOFError异常

send(obj)
	向另一端发送信息

	
4.进程池
import multiprocessing, time, os

def f(i):
    start = time.time()
    print("Process %s is running." % multiprocessing.current_process().name)
    result = 100**10000000
    end = time.time()
    print("Process %s done, cost time %d." % (multiprocessing.current_process().name, end-start))

if __name__ == "__main__":
    print("Process %s is running." % multiprocessing.current_process().name)
    start_totle = time.time()
    pool = multiprocessing.Pool(4)
    for i in range(10):
        pool.apply_async(f, args=(i,))
    pool.close()
    pool.join()
    end_totle = time.time()
    print("总共用时%d s." % (end_totle-start_totle))




线程：CPU中的最小调度单元，同一进程的不同线程，共享同一内存空间

锁：由于同一进程下的线程共享同一内存空间，同时读取内容会造成混乱，所以需要使用互斥锁防止同时读取

threading模块
function:
active_count()
	当前alive线程数量

current_thread()
	返回当前运行的线程Thread对象

enumerate()
	当前alive线程Thread对象列表

class 
Thread

variable:
name
	获取或配置线程名称

daemon
	判断或设置守护线程

method：
__init__(self, group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)
	创建一个线程实例
	group - 保留，用于将来ThreadGroup类的实现
	target - function，线程中执行的方法. 实际被run()调用
	name - str类型，线程的名称，默认为'Thread-<N>'
	args - tuple类型，传入target方法的位置参数
	kwargs - dict类型，传入target方法的关键字参数
	daemon - bool类型，设置线程是否为守护线程。默认继承自主线程，主线程非守护线程

is_alive()
	线程是否存活

join(timeout=None)
	将创建的线程阻塞主线程，阻塞指定时间或阻塞直到线程terminate
	timeout - float格式，阻塞指定时间

run()
	线程实际执行的方法
	在子类实现中必须被重写

start()
	启动线程，使run()被调用
	当多次调用同一个线程的该方法时，抛出Runtimeerror异常

class
Lock

method:
__init__()
	初始化锁

acquire(blocking=True, timeout=-1)
	请求锁，获取后置于locked状态
	blocking - 当为True时，如果请求的锁状态为locked，进行排队等候释放锁；当为False，如果请求的锁状态为locked，直接放弃请求
	timeout - 排队等候时间，超过该时间放弃。默认为-1，代表不限制等候时间

release()
	释放锁，释放后置于unlock状态
	如果试图释放locked状态的锁，将会引发RuntimeError异常

locked()
	查看锁的状态

**并发问题：当多个线程同时读取相同变量时，会导入互相干扰，得出错误结果。
**问题解决1：确保函数使用局部变量可避免该问题
**问题解决2：使用锁，使同一时间变量只能被一个线程访问

采用多进程(多线程)的条件：计算密集型任务 or I/O密集型任务
多进程：线程切换需要消耗CPU，并且由于GIL特性无法并行执行多个线程，所以计算密集型任务适合多进程

多线程：I/O密集型任务由于大部分时间处于等待I/O传输(由于CPU运算速度远高于I/O速度)，所以此时切换线程会大幅增加计算机性能，且由于线程的共享空间特性，所以I/O密集型任务使用多线程

并发和并行的差异：
并发(concurrency)：将时间段切分为多个时间片，在时间片执行不同内容，但同一时间片只执行一个呢绒。多线程和多进程都属于并发

并行(parallel)：不同任务在不同CPU上同一时间点同时执行。python只有多进程属于并行


示例1 - 主线程与子线程分开
from threading import Thread
import time, os

def sub_thread():
	print("sub-thread begin")
	print("sub-thread pid: %s" % os.getpid())
	time.sleep(10)
	print("sub-thread end")

print("main-thread begin")
print("main-thread pid: %s" % os.getpid())
thread = Thread(target=sub_thread)
thread.start()
print("main-thread end")


示例2 - 主线程等待子线程中断
from threading import Thread
import time, os

def sub_thread():
    print("sub-thread begin")
    print("sub-thread pid: %s" % os.getpid())
    time.sleep(10)
    print("sub-thread end")

print("main-thread begin")
print("main-thread pid: %s" % os.getpid())
thread = Thread(target=sub_thread)
thread.start()
thread.join()
print("main-thread end")


示例3 - 子线程随着主线程终结
from threading import Thread
import time, os

def sub_thread():
    print("sub-thread begin")
    print("sub-thread pid: %s" % os.getpid())
    time.sleep(10)
    print("sub-thread end")

print("main-thread begin")
print("main-thread pid: %s" % os.getpid())
thread = Thread(target=sub_thread, daemon=True)
thread.start()
print("main-thread end")


示例4 - Thread子类实现线程功能
import threading

class SubThread(threading.Thread):
    def __init__(self, args=0):
        super().__init__()
        self._args = args

    def run(self):
        print("current thread name: %s." % threading.current_thread().name)
        result = self._args**100
        print("%d^100结果: %d." % (self._args, result))

thread = SubThread(args=2)
thread.start()
thread.join()
print("thread over")


示例5 - 线程锁
from threading import Thread
import threading
import time, os

class Account:
	def __init__(self):
		self.balance = 0

	def add(self, lock):
		lock.acquire()
		for i in range(1000):
			self.balance += 1
			print("the %d th add, result is: %d" % (i, self.balance))
		lock.release()

	def delete(self, lock):
		lock.acquire()
		for i in range(1000):
			self.balance -= 1
			print("the %d th delete,result is: %d" % (i, self.balance))
		lock.release()

if __name__ == "__main__":
	account = Account()
	lock = threading.Lock()
	thread1 = Thread(target=account.add, args=(lock,))
	thread2 = Thread(target=account.delete, args=(lock,))
	
	# 启动线程
	thread1.start()
	thread2.start()

	# 阻塞主线程
	thread1.join()
	thread2.join()

	print("The final balance is: %d" % account.balance)


6.Queue队列(Queue为线程安全, 内部实现锁机制)
import threading, queue, time, random

class Producer(threading.Thread):
	def __init__(self, name=None, queue=None):
		super().__init__(name=name)
		self._queue = queue

	def run(self):
		for i in range(5):
			self._queue.put(i)
			print("%s is producing %d to queue." % (self.name, i))
			time.sleep(random.randrange(2))
		print("producer done")

class Consumer(threading.Thread):
	def __init__(self, name=None, queue=None):
		super().__init__(name=name)
		self._queue = queue

	def run(self):
		for i in range(5):
			n = self._queue.get()
			print("%s is producing %d to queue." % (self.name, n))
			time.sleep(random.randrange(2))
		print("consumer done")
		
queue = queue.Queue()
producer = Producer("producer", queue)
consumer = Consumer("consumer", queue)
producer.start()
consumer.start()
producer.join()
consumer.join()
print("everything is done")
		
